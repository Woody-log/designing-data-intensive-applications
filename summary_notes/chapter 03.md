# Chapter 3. 저장소와 검색

- 데이터 베이스가 수행하는 가장 기본적인 작업
  - 어떤 데이터를 받으면 **저장** -> 어떻게 저장하는가?
  - 요청된 데이터를 **제공** -> 어떻게 다시 찾는가?
- 사용 가능한 여러 저장소 엔진 중, **애플리케이션에 적합한 엔진을 개발자가 선택**해야한다
  - 특정 작업부하 유형에서 좋은 성능을 낼수 있도록!
  - 이를 위해 작업 방식에 대해 이해할 필요가 있다.
- 저장소 엔진
  - 관계형 데이터 베이스
  - NoSQL
  - 로그 구조 계열 저장소 엔진
  - 페이지 지향 계열 저장소 엔진



## 1. 데이터베이스를 강력하게 만드는 데이터 구조

- 가장 간단한 수준의 데이터 베이스를 두 개의 bash 함수로 구현

```bash
#!/bin/bash

db_set () {
    echo "$1,$2" >> database
}

db_get () {
     grep "^#$1," database | sed -e "s/^$1,//" | tail -n 1
}
```

- 일반적으루 파일 추가 작업은 매우 효율적 -> 위의 경우 db_set은 간단한 작업의 경우 실제로 꽤 좋은 성능을 낸다
  - 하지만 실제로는 동시성 제어, 디스크 공간 회수, 오류 처리 등등을 고려해야 함
  - 로그(**연속된 추가 전용 레코드**)는 믿기지 않을 정도로 유용
- db_get 함수는 많은 레코드가  있을 경우 성능이 매우 나쁘다
  - 매번 처음부터 끝까지 스캔: O(n)
  - 이를 해결할 데이터 구조 -> **색인**
- 색인
  - 의미: 이정표 역할로 원하는 데이터의 위치를 찾는 데 도움 주는 부가적 메타 데이터를 유지하는 것
  - 기본 데이터에서 파생된 추가적인 구조 -> 내용에는 영향을 미치지 않고 질의 성능에만 영향을 미친다
  - 모든 종류의 색인은 갱신 때문에 쓰기 속도를 느리게 만든다 -> **읽기와 쓰기 속도 사이의 트레이드 오프**
  - 앱 개발자나 디비 관리자가 수동으로 색인을 선택

<br>

### 1.1. 해시 색인

- 키-값 데이터: 색인할 수 있는 유일한 종류의 데이터는 아니지만 매우 일반적이고, 더욱 복잡한 색일을 위한 구성 요소로 유용
  - 대부분의 프로그래밍 언어에서 볼 수 있는 사전 타입과 매우 유사
  - 보통 해시 맵으로 구현 -> 인메모리 데이터 구조를 사용해보자

- 가장 간단한 색인 전략: 해시 테이블

  - 키를 데이터 파일의 바이트 오프셋에 매핑
  - 관련 설명: [링크](https://parksb.github.io/article/29.html), 근데 사실 이부분 잘 모르겠음 .... ㅜㅜ
  - 파일에 새로운 키-값 쌍을 추가할 대마다 해시값을 갱신해야 함
  - 조회할 때는 해시 맵으로 오프셋을 찾아 위치를 구하고 값을 읽는다
  - 비트캐스크(리악Riak의 기본 저장소 엔진)가 근본적으로 사용하는 방식
    - 그들이 무엇인지는 모름 ....
  - 비트 캐스크는 해시 맵을 전무 메모리에 유지 -> 고성능 유지
  - 키 값이 자주 갱신될 때 적합하다
  - 근데 계속 추가만 하면 디스크 공간이 부족 -> 세그먼트로 로그를 나누고 컴팩션
    - 이 방식은 키-값에 대해 덮어쓰지 않음에 주목.

  ![Figure 3-2. Compaction of a key-value update log (counting the number of times each cat video was played), retaining only the most recent value for each key](https://notes.shichao.io/dda/figure_3-2_600.png)

  ![Figure 3-3. Performing compaction and segment merging simultaneously.](https://notes.shichao.io/dda/figure_3-3_600.png)

  - 실제 구현에서 중요한 문제들
    - 파일 형식: csv보다는 바이너리가 빠르고 간단 (사실 이해 못함)
    - 레코드 삭제: 삭제 레코드는 따로 툼스톤으로 마킹해서 무시하게 해야함
    - 고장 복구: 세그먼트로부터 복구는 고통스러으므로 인메모리 해시 맵 스냅숏을 디스크에 저장
    - 부분적 레코드 쓰기: 체크섬을 통해 손상 탐지
    - 동시성 제어: 하나의 쓰기 스레드만 사용 -> 쑨차적 쓰기만 엄격하게
  - 왜 덮어쓰지 않을까? 다 이유가 있다 (하나도 이해 못함)
    - 순차적이라서 무자가위 쓰기보다 훨씬 빠르다
    - 동시성과 고장 복구가 간단하다 
    - 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있다
  - 해시 테이블의 제한 사항
    - 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다.
    - 범위 질의에 효율적이지 않다. 
    - 다음은 이런 제한이 없는 색인 구조

<br>

### 1.2. SS테이블과 LSM트리

- 일련의 키-값 쌍을 **키로 정렬**해보자: **정렬된 문자열 테이블(SS 테이블)**
  - 또한 각 키는 각 병합된 세그먼트 파일 내에 한 번만 등장(컴팩션으로 보장)
- 해시 색인에 대해 장점
  - 세그먼트 병합이 효과적(머지소트와 유사)
  - 희소 색인도 무관하다(순서를 아니까)
  - 요청 범위 내의 레코드를 압축 -> 디스크 공간 절약 & I/O 대역폭 사용을 줄임

**1.2.1. SS 테이블 생성과 유지**

- 레드 블랙 트리나 AVL 트리 등을 이용하면 임의 순서로 키를 삽입하고 정렬된 순서로 다시 읽을 수 있다
- 저장소 엔진을 다음과 같이 만든다. (잘 이해 못함)
  - 쓰기가 들어오면 인메모리 균형 트리(**멤테이블**)에 추가한다.
  - 멤테이블이 임계값을 초과하면 SS테이블 파일로 디스크에 기록
  - 읽기 요청이 오면, 멤테이블 -> 최신 세그먼트 -> 두번째로 오래된 세그먼트 ... 순으로 찾는다
  - 가끔 병합과 컴팩션을 백그라운드로 실행한다
- 멤테이블은 손실될 수 있기 때문에 분리된 로그를 디스크에 유지하고, 복원할 때 로그를 사용한다

**1.2.2. SS테이블에서 LSM 트리 만들기**

- 여기 기술된 알고리즘은 기본적으로 레벨DB와 록스DB 등에서 사용된다.
- LSM 저장소 엔진: 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진
  - 로그 구조화 파일 시스템의  초기 작업의 기반
- 루씬은 ES나 솔라에서 사용하는 전문 검색 색인 엔진
  - 용어 사전을 저장하기 위해 유사한 방법 사용 (훨씬 더 복잡)
  - 키는 단어(**용어**), 값은 단어를 포함한 모든 문서의 ID 목록(**포스팅 목록**)
  - 둘 사이의 매핑은 SS테이블 같은 정렬 파일에 유지하고 필요할 때 백그라운드에서 병합

**1.2.3. 성능 최적화**

- LSM 트리 알고리즘은 존재하지 않는 키를 찾을 때 느릴 수 있다
  - **블룸 필터**(집합 내용을 근사한 메모리 효율적 데이터 구조를 보통 추가적으로 사용한다
- 압축/병합하는 순서와 시기를 결정하는 다양한 전략
  - 크기 계층: Hbase와 카산드라가 사용
    - 상대적으로 좀 더 새롭고 작은 SS 테이블을 오래됐고 큰 SS테이블에 연이어 병합
  - 레벨 컴팩션:  레벨DB와 록스DB, 카산드라에서 사용
    - 키 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 "레벨"로 이동 -> 점진적 진행으로 디스크 덜 사용
- LSM 트리의 기봄 개념은 백그라운드에서 연쇄적으로 SS테이블을 지속적으로 병합하는 것
  - 데이터가 가능한 메모리보다 훨씬 더 크더라도 효과적
  - 데이터가 정렬된 순서로 있으면 범위 질의를 효율적으로 실행
  - 순차적이기 때문에 LSM트리가 매우 높은 쓰기 처리량을 보장

<br>

### 1.3. B 트리

- 가장 널리 사용되는 색인 구조
- SS테이블과는 키로 정렬된 키-값 쌍을 유지한다는 것 정도만 비슷하다
- B 트리는 전통적으로 4KB(혹은 거 큰)의 고정 크기 **블록**이나 **페이지**로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기
  - 고정 크기 블록이라서 근본적으로 하드웨어와 조금 더 밀접한 관련이 있다
  - 각 페이지는 주소나 위치를 이용해 식별할 수 있다
  - 하나의 페이지가 다른 페이지를 참조할 수 있다

- 한 페이지는 B 트리의 **루트root**로 지정된다.
  - 색인에서 키를 찾을 땐 루트에서 시작한다. 이하 그림 참조
  - 최종적으로는 개별 키(**리프 페이지**)를 포함하는 페이지에 도달한다
  - B 트리의 한 페이지에서 하위 페이지를 참조하는 수를 **분기 계수**라고 한다 
  - 아래 그림의 분기 계수는 6이고, 실제로는 보통 수백 개에 달한다

![Figure 3-6. Looking up a key using a B-tree index.](https://notes.shichao.io/dda/figure_3-6_600.png)

- 이 알고리즘은 트리가 계속 **균형**을 유지하는 것을 보장한다
  - n개의 키를 가진 B 트리는 깊이가 항상 O(log n)이다

**1.3.1. 신뢰할 수 있는 B 트리 만들기**

- B 트리는 새로운 데이터를 디스크 상의 페이지에 **덮어쓴다**
  - 페이지 위치는 변경하지 않는다고 가정 -> 페이지를 덮어쓰더라도 페이지를 가리키는 모든 참조는 온전히 남는다
  - 파일에 추가만 하고 변경하지 않는 로그 구조화 색인과는 다르다!
- 덮어쓸 때 주의: 분할된 두 페이지를 기록하고 두 하위 페이지의 참고를 갱신해야 한다
  - 일부 페이지만 기록하고 db가 고장나면 색인이 훼손될 수 있어 위험하다 (예컨대 **고아 페이지**가 발생할 수 있다)
- DB가 고장났을 때 스스로 복구하게끔 하려면 일반적으로 디스크 상에 **쓰기전 로그WAL**(**재실행 로그**)라는 데이터 구조를 추가
  - 트리 페이지의 변경된 내용을 적용하기 전에 모든 B 트리의 변경사항을 기록하는 추가 전용 파일
- 같은 자리의 페이지를 갱신하는 건 **동시성 제어**로 골칫거리다
  - 보통 **래치**(가벼운 잠금)로 트리의 데이터 구조를 보호한다

**1.3.2. B 트리 최적화**

- WAL 대신 쓰기 시 복사 방식
  - 변경도니 페이지는 다른 위치에 기록하고 트리에 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가리킴 
    -> 동시성 제어에도 유용
- 전체 키를 저장하는 대신 키를 축약해 쓴다.
  - 페이지 하나에 키를 더 많이 채우면 더 높은 분기 계수를 가지고 깊이 수준이 낮춰진다 (B+ 트리)
- 리프 페이지를 디스크 상에 연속된 순서로 배치 but 트리가  커지면 순서 유지가 어렵다
  - 질의가 정렬된 순서로 스캔 시에 연속된 페이지를 찾기 때문에 공간적으로 가까운 게 좋음
- 트리에 포인터 추가. 예컨대 각 리프 페이지는 좌우 형제 페이지에 대한 참조를 가진다
- **프랙탈 트리** -> 디스크 찾기를 줄이기 위해 로그 구조화 개념을 일부 빌렸다

<br>

### 1.4. B 트리와 LSM 트리 비교

- 경험적으로 LSM 트리는 쓰기가 빠르고 B 트리는 읽기가 더 빠르다고 여겨진다.
  - LSM은 각 컴팩션 단계의 여러 데이터 구조와 SS테이블을 확인하기 때문에 느림

- 실제로는 작업부하의 세부 사항에 민감하기 때문에 테스트해봐야 안다

**1.4.1. LSM 트리의 장점**

- B 트리는 모든 데이터 조각을 최소 2번 기록해야 한다
  - 해당 페이지 내 몇 바이트만 바뀌어도 한 번에 전체 페이지를 기록해야 하는 오버헤드도 존재
- SS 테이블 또한 반복된 컴팩션과 병합으로 여러 번 데이터를 다시 쓴다
- **쓰기 증폭**:db에 쓰기 한 번이 db 수명 동안 여러 번의 쓰기를 야기하는 효과
  - SSD는 덮어쓰기 횟수가 제한 -> 쓰기 증폭이 특별한 관심사
- LSM 트리는 보통 B 트리보다 **쓰기 처리량을 높게 유지**할 수 있다 (케바케는 있음)
- LSM 트리는 **압축률이 더 좋다**
  - B 트리는 파편화로 사용하지 않는 디스크 공간 일부가 남는다
  - LSM 트리는 주기적으로 파편화를 없애기 위해 SS 테이블을 다시 기록
  - 레벨 컴팩션을 사용하면 더욱 그렇다

- 대다수의 SSD의 펌웨어는 내장 저장소 침에서 **임의 쓰기를 순차 쓰기로 전환**하기 위해 로그 구조화 알고리즘 사용
  - 따라서 저장소 엔진이 쓰기 패턴이 SSD에 미치는 영향은 분명치 않다
  - 낮은 쓰기 증폭과 파편화 감소는 SSD에 훨씬 유리

**1.4.2. LSM 트리의 단점**

- 컴팩션이 때로는 진행 중인 읽기/쓰기 성능에 영향
  - 이하 이해 못함 ....
  - 결론 LSM은 꼬리 응답 시간이 때때로 꽤 길다
- 또 다른 컴팩션 문제 -> 높은 쓰기 처리량
  - 디스크의 쓰기 대역폭은 유한한데 다른 거랑 쓰기 대역폭을 공유 -> db가 커질수록 컴팩션에 더 많은 대역폭이 할당된다
- 컴팩션이 유입 쓰기 속도를 따갈 수 없을 때도 있다
  - 병합되지 않은 세그먼트 수는 디스크 공간을 다 잡아먹고 자연히 이를 확인해야 하는 읽기도 느려진다
  - 명시적 모니터링이 필요하다
- B 트리의 장점은 각 키가 색인의 한 곳에만 정확하게 존재한다는 것
  - 로그 구조화는 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다
  - 이하 이해못함
- B 트리는 DB 아키텍쳐에 뿌리내렸고 사라질 것 같지 않다
  - 새로운 데이터 저장소에서는 로그 구조화 색인이 점점 인기를 얻고 있다
  - 빠르고 쉬운 규칙은 없으니 테스트를 통해 경험적으로 결정하자

### 1.5. 기타 색인 구조

- 키-값 색인의 대표적인 예는 관계형 모델의 **기본키** 색인
  - 기본키를 통해 관계형 테이블에서 하나의 로우, 문서 db에서 하나의 문서, 그래프 db에서 하나의 정점을 고유하게 식별
- **보조색인** 또한 매우 일반적
  - 보통 효율적으로 조인을 수행하는데 결정적 역할 (그리고 where도?)
  - 기본키와 주요 차이점은 키가 고유하지 않다는 것
    - 색인의 각 값에 일치하는 로우 식별자 목록을 만들거나
    - 로우 식별자를 추가해 각 키를 고유하게 만드는 방법이 있다
    - B 트리와 로그 구조화 색인 모두에서 둘 다 사용 가능하다

**1.5.1. 색인 안에 값 저장하기**

- 키: 질의가 검색하는 대상
- 값: 질문의 실제 로우(문서, 정점) or 다른 곳에 저장된 로우를 가리키는 참조
  - 후자의 경우 로우가 저장된 곳을 **힙 파일**이라 하고 특정 순서 없이 데이터를 저장한다
  - 여러 보조 색인이 존재할 때 데이터 중복을 피할 수 있기 때문에 힙 파일 접근이 일반적이다
- 힙 파일 접근은 키 변경 없이 값을 갱시할 때 효율적
- 색인에서 힙 파일로 다시 이동하는 건 읽기 성능에 구리기 때문에 때에 따라 색인 안에 바로 색인된 로우를 저장
  - 이를 **클러스터드 색인**이라고 한다
  - mySQL의 InnoDB에서는 기본키가 항상 클러스터드 색인, 보조 색인은 기본키 참조
  - MsSQL은 테이블 당 하나의 클러스터드 색인 지정 가능
- 클러스터드와 비클러스터드 사이의 절충안을 **커버링 색인** 혹은 **포괄열이 있는 색인**이라 한다
  - 색인 안에 테이블에 칼럼 일부 저장 -> 이런 경우를 색인이 질의를 **커버**했다고 한다.
- 클러스터드와 커버링은 읽기 성능을 높이지만 추가적인 저장소가 필요 + 쓰기 과정에 오버헤드 발생
  - 앱 단에서 복제로 인한 불일치 파악 불가 (?)

**1.5.2. 다중 칼럼 색인**

- 지금까지 설명한 색인은 하나의 키만 값에 대응 -> 다중 컬럼 동시 질의에 충분치 않다
- 다중 칼럼 색인의 가장 일반적인 유형은 **결합 색인**
  - 하나의 칼럼에 다른 칼럼을 추가하는 방식으로 하나의 키에 여러 필드를 단순히 결합
  - (성, 이름)을 키로, 전화번호를 값으로 하는 전화번호부와 유사한 구성
  - 순서가 정렬돼 있어 특정 성이나 성이름 조합 모두에 색인을 사용할 수 있다
  - 하지만 특정 이름으로 검색은 잘 안됨
- **다차원 색인**은 한 번에 여러 칼럼 질의할 때 조금 더 일반적이다
  - 위도/경도 검색이 대표적인 예
  - 표준 B 트리나 LSM 트리 색인은 이런 유형의 질의에 효율적으로 응답 불가
  - 한 가지 방법: **이차원 위치를 공간 채움 곡선으로 단일 숫자로 변환한 뒤 일반 B 트리 색인을 사용하는 것**
    - 좀 더 일반적인 건 R 트리같은 전문 공간 색인 사용 -> 포스트GIS

**1.5.2. 전문 검색과 퍼지 색인**

- 유사하거나 애매모호한 질의에 대한 응답은 다른 기술이 필요하다
- 전문 검색 엔진의 경우
  - 동의어로 질의를 확장하거나
  - 동일한 문서 내에 인접한 단어를 검색하거나
  - 언어학적으로 텍스트를 분석하기도 한다
  - 루씬은 오타에 대처하기 위한 편접 거리내 단어를 검색할 수 있다 (SS테이블 같은 구조 사용)
  - 이하 이해 못함(91p 상단)
- 그 밖의 퍼지 검색 기술은 문서 분류 및 머신러닝의 방향으르 진행된다

**1.5.3. 모든 것을 메모리에 보관**

- 앞서 나온 모든 데이터 구조는 디스크 한계에 대한 해결책. 디스크는 메인 메모리와 비교해 다루기 어렵다.
- 그럼에도 디스크는 **지속성**(비휘발성)이 있고 가격이 더 **저렴**하다
- 램이 저렴해져서 **인메모리 db**가 개발됐다
- 맴캐시드 같은 경우 키-값 저장소는 장비 재식시 데이터 손실을 허용하는 캐시 용도로만 사용된다.
- 지속성을 목표로 하는 경우
  - 배터리 전원 공급 RAM과 같은 특수 하드웨어 사용
  - 디스크에 변경 사항의 로그를 기록하거나
  - 디스크에 주기적인 스냅숏을 기록하거나
  - 다른 장비에 인메모리 상태를 복제하는 방법 등
- 디스크 기록은 쉽게 백업이 되고 위부 유틸리티로 검사와 분석 가능해서 좋다

- 볼트DB, 멤SQL, 오라클 타임즈텐 같은 제품은 관계형 모델의 인메모리 db
  - 램클라우드는 지속성 있는 오픈소스 인메모리 키-값 저장소
  - 레디스와 카우치베이스는 비동기로 디스크에 기록 -> 약한 지속성
- 인메모리 db의 성능 장점은 디스크에서 읽지 않아도 된다는 게 아니다 (?!)
  - 디스크 기반도 디스크 블록을 메모리에 캐시 -> 디스크에서 읽을 필요가 없다
  - 오히려 오버헤드땜에 더 빠를 수도 있다
  - 대신 인메모리db는 디스크 기반이 못하는 데이터 모델을 제공한다
    - 레디스는 우선순위 큐와 셋과 같은 다양한 데이터 구조를 db와 같은 인터페이스로 제공
    - 메모리에 모든 데이터 유지 -> 구현이 비교적 간단
- 인메모리 db 아키텍쳐가 오버헤드 없이 가용 메모리보다 큰 데이터셋을 지원하게 확장도 가능하다
  - **안티 캐싱**: 메모리가 부족할 때 최근에 안 쓴 데이터를 디스크로 보낸다
  - 가상 메모리와 스왑과도 비슷하지만 db는 개별 레코드 단위로 작업할 수 있어 OS보다 더 효율적으로 메모리를 관리한다
  - 하지만 전체 색인은 메모리에 있어야 한다
- 비휘발성 메모리가 발전하면 또 시국이 변할 것이다



<br>

***

<br>

## 2. 트랜잭션 처리나 분석?

- 초창기 비즈니스 데이터 처리는 db 쓰기가 보통 커머셜 트랜잭션(상거래)에 해당했다
- 비금전 거래까지 확장됐어도 **트랜잭션**이란 용어는 여전히 논리 단위 형태로서 읽기와 쓰기 그룹을 나타낸다
  - 트랜잭션이 반드시 ACID(원자성, 일관성, 격리성, 지속성)일 필요는 없다
  - 주기적으로 수행되는 일괄 처리(batch job?)와 달리 지연 시간이 낮은 읽기/쓰기를 가능하게 한다는 의미이다
- db가 많은 여러 종류의 데이터를 사용했어도 기본적인 접근 패턴은 비즈니스 트랜잭션 처리와 유사하다
  - 색인을 이용해 일부 키에 대한 적은 수의 레코드를 찾는다
  - 레코드는 사용자 입력을 기반으로 삽입되거나 갱신된다
  - 이러한 앱은 대화식이기 때문에 **온라인 트랜잭션 처리OLTP**라고 한다
- db를 **데이터 분석**에도 점점 더 많이 사용하기 시작했다
  - 이 경우 트랜잭션과 접근 패턴이 많이 다른다
  - 많은 수의 레코드를 스캔해 레코드 당 일부 칼럼만 읽어 집계 통계를 계산한다
  - 이런 질의는 BI라 불리며 더 나의 의사결정을 하게끔 돕는 보고서를 제공
  - 이런 db 사용 패턴을 **온라인 분석처리OLAP**라 한다
- 둘 사이의 특성 비교 표

| 특성           | OLTP                                             | OLAP                                                 |
| -------------- | ------------------------------------------------ | ---------------------------------------------------- |
| 주요 읽기 패턴 | 질의당 적은 수의 레코드, 키 기준으로 가져옴      | 많은 레코드에 대한 집계                              |
| 주요 쓰기 패턴 | 임의 접근. 사용자 입력을 낮은 지연 시간으로 기록 | 대규모 불러오기(bulk import, ETL) 또는 이벤트 스트림 |
| 주요 사용처    | 웹 앱을 통한 최종 사용자/소비자                  | 내부 분석가                                          |
| 데이터 표현    | 데이터의 최신 상태(현재 시점)                    | 시간이 지나며 일어난 이벤트 이력                     |
| 데이터셋 크기  | 기가~테라                                        | 테라~페타                                            |

- 처음에는 동일한 db로 모두 처리. SQL이 매우 유연했다
  - 8~90년대 개별 데이터베이스(?)에서 분석을 수행하기 시작 -> 데이터 웨어하우스



### 2.1.데이터 웨어하우징

- 대개 기업은 수삽가지의 트랜잭션 처리 시스템을 갖추고 있다
  - 이런 시스템은 복잡해서 유지보수를 위한 팀이 필요하기 때문에 각 시스템은 보통 서로 독자적으로 운영된다.
- OLTP 시스템은 대단히 중요해 일반적으로 **높은 가용성과 낮은 지연 시간의 트랜잭션 처리**를 기대한다
  - 그래서 분석가가 즉석 분석질의ad hoc analytic query하는 걸 싫어한다. 대개 비싸기 때문에
- 데이터 웨어하우스는 분석가들이 OLTP에 영향없이 맘껏 질의할 수 있는 개별 데이터베이스 (읽기 전용 복사본)
  - 데이터는 OLTP db에서 추출**E**하고 분석 친화적인 스키마로 변환**T**하여 깨끗이 정리한 다음 웨어하우스에 적재**L**한다
  - 소규모 기업은 OLTP 시스템이 다양하지 않고 데이터의 양이 적기 때문에 웨어하우스가 따로 없다
  - 소규모 기업에서는 간단한 일이 대기업에서는 많은 노력을 필요로 한다
  - 개별 데이터 웨어하우스를 사용하는 큰 장점은 분석 접근 패턴에 맞게 최적화할 수 있다는 점
  - 색인 알고리즘은 OLTP에서 잘 작동하지만 OLAP에서 구리다

**2.1.1. OLTP db와 데이터 웨어하우스의 차이점**

- **SQL은 일반적으로 분석 질의에 적합** -> 데이터 웨어하우스의 데이터 모델은 가장 일반적인 관계형 모델을 사용한다
- 표먼적으로 OLTP와 데이터 웨어하우스는 모두 SQL 질의 인터페이스를 지원해 비슷해보인다
  - 하지만 각기 다른 질의 패턴에 맞게 최적화되어 시스템 내부는 완전히 다르다
  - 보통 데이터베이스 벤더는 둘 다 보다는 둘 중 하나 지원에 중점을 둔다
- 상용 라이선스의 데이터 웨어하우스 벤더
  - 테라데이터, 버티카, SAP 하나, 파르에이셀(운영버전: 아마존 레드시프트)
- 오픈소스 SQL  온하둡 프로젝트
  - 아파치 하이브, 스파크 SQL, 클라우데라 임팔라, 페이스북 프레스토,아파치 타조, 아파치 드릴 등



### 2.2. 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마

- 분석에서는 데이터 모델의 다양성이 훨씬 적다
- 많은 데이터 웨어하우스는 별모양 스키마(차원 모델링)로 알려진 상당히 정형화된 방식 지원
  - 별 모양 스키마는 테이블 관계가 시각화될 때 사실 테이블이 가운데에 있고 차원 테이블이 둘러싸고 있음에서 유래
  - **사실 테이블**의 각 로우는 특정 시각에 발생한 이벤트에 해당한다
    - 웹 사이트 트래픽이라면 각 로우는 페이지 뷰나 사용자 클릭에 해당한다
    - 보통 사실은 개별 이벤트를 담아 분석의 유연성은 극대화되지만 테이블이 매우 커질 수 있다
  - 사실 테이블의 어떤 칼럼은 **차원 테이블**이라 부르는 다른 테이블을 가리키는 외래 키 참조이다
    - 차원은 이벤트의 속성인 5W1H를 나타낸다
    - 그 외에 다른 여러 속성-공휴일과 같은 추가 적인 정보 등을 나타낼 수 있다.
  - 그림 3-9의 예제 스키마 참조

- 위 템플릿의 변형은 **눈꽃송이 모양 스키마**로, 차원이 하위차원으로 더 **세분화**된다.
  - 예컨대 브랜드와 제품 범주 테이블을 분리해 제품 테이블이 브랜드를 다른  테이블에서 외래 키로 참조한다
  - 눈꽃송이가 더 정규호하됐지만 별 모양이 더 작업하기 쉬워 선호된다.

### 2.3. 칼럼 지향 저장소

- 사실 테이블은 겁나 무거워서 저장하고 질의하기가 어려운 문제다
  - 차원 테이블은 보통 수백만 정도로 적어서 이번 장에서는 주로 사실 저장에 집중
- 사실 테이블은 보통 100개 이상의 칼럼을 가지지만, 데이터 웨어하우스 질의는 보통 4~5개만 접근한다
  - 대부분의 OLTP db에서는 **로우 지향**방식으로 데이터를 배치한다.
    - 테이블에서 한 로우의 모든 값은 서로 인접하게 저장된다
  - **칼럼 지향 저장소**의 기본 개념은 간단하다
    - 각 칼럼 별로 모든 값을 함께 저장한다 -> 질의에 사용되는 칼럼만 읽고 구분 분석하면된다
    - 예를 들어 **파케이parquet**는 구글의 드레멜을 기반으로 한 문서 데이터 모델을 지원하는 칼럼 저장소 형식이다
    - 칼럼 지향 저장소는 각 카럼 파일에 포함된 로우가 모두 같은 순서인 점에 의존한다

**2.3.1. 칼럼 압축**

- 각 칼럼에서는 많은 값이 반복해서 나타나기 때문에, 칼럼 지향 저장소는 대개 **압축에 적합**하다
- 그 중 한가지 기법은 데이터 웨어하우스에서 특히 효과적인 **비트맵 부호화**이다 (그림 3-11 참조)
  - n개의 고유 값을 가진 칼럼을 가져와 n개의 개별 비트맵으로 전환 (원핫인코딩)
  - 추가적으로 런 렝스 부호화
- 그 외에 다양한 압축 스키마가 있다
- 카산드라와 HBase는 빅테이블로부터 내려오는 **칼럼 패밀리**(!=칼럼 지향적) 개념이 있다. 
  - 각 패밀린 로우 키에 따라 로우와 모든 칼럼을 함께 저장하며 칼럼 압축을 사용하지 않는다 -> 로우 지향

**2.3.2. 메모리 대역폭과 벡터화 처리**

- 수백만 로우를 스캔할 때는 **디스크로부터 데이터를 가져오는 대역폭이 큰 병목**이다
- 다른 사항들도 중요하다
  - 메인 메모리에서 CPU 캐시로 가는 대역폭의 효율적 사용
  - CPU 명령 처리 파이프라인에서 분기예측 실패와 버블을 피해야 한다
  - 단일 명령 다중 데이터 명령을 사용하게끔 신경써야 한다
- 칼럼 저장소 배치는 CPU 주기를 효율적으로 사용하기에도 적합하다
  - 압축된 칼럼 데이터를 CPU의 L1 캐시에 딱 맞게 덩어리로 나누어 가져오는 작업을 타이트 루프(?)에서 반복한다
  - 칼럼 압축으로 같은 양의 L1 캐시에 칼럼의 더 많은 로우를 저장할 수 있다
  - 비트 AND나 OR같은 연산자는 압축된 칼럼 데이터 덩어리에 바로 연산할 수 있게 설계 -> 벡터화 처리

**2.3.3. 칼럼 저장소의 순서 정렬**

- 칼럼 저장소는 로우가 저장되는 순서가 중요하지 않고, 삽입된 순서로 저장하는 게 제일 쉽다
  - 근데 순서 도입해 색인 메커니즘으로 사용할 수 있다
- 각 칼럼을 독립적으로 정렬할 수는 없다. 모든 칼럼은 같은 순서로 적재되어야 하므로
  - db관리자는 공통 질의에 대한 지식을 이용해 정렬해야 하는 칼럼을 선택할 수 있다
- 한 칼럼을 정렬한 다음, 그 칼럼의 같은 값에 대해 두 번째 칼럼에서 정렬할 수 있다
- 정렬은 칼럼 압축에 도움이 된다
  - 그리고 그 효과는 첫번째 정렬 키에서 가장 강력하다 

**2.3.4. 다양한 순서 정렬**

- 질의에 따라 효과적인 정렬이 다르므로 같은 데이터를 다양한 방식으로 정렬할 수 있다
  - C-store에서 소개되어 버티카에서 태책되었다.
  - 이는 로우 지향 저장에서 여러 2차 색인을 갖는 것과 약간 비슷하다

**2.3.5. 칼럼 지향 저장소에 쓰기**

- B 트리 사용과 같은 update-in-place는 압축된 칼럼에서 불가능하다
- LSM 트리가 좋은 해결책이 된다 (이하 이해못함)
  - 모든 쓰기는 먼저 인메모리 저장소로 이동해 정렬된 구조에 추가 후 디스크에 쓸 준비한다
  - 로우 지향 칼럼 지향은 중요 X
  - 충분한 쓰기를 모으면 디스크의 칼럼파일에 병합하고 대량으로 새로운 파일에 기록한다

- 질의는 디스크의 칼럼 데이터와 메모리의  최근 쓰기를 모두 조사해 결합

**2.3.6. 집계: 데이터 큐브와 구체화 뷰**

- 동일한 **구체화 집계**(count, sum, avg, ...)를 다양한 질의에서 사용한다면 매번 계산하는 것은 낭비다
- 이런 캐시를 만드는 한 가지 방법은 **구체화 뷰**다.
  - 구체화 뷰는 디스크에 기록된 질의 결과의 실제 복사본
  - 가상 뷰는 단지 질의를 작성하는 단축키
  - 원본 데이터를 변경하면 구체화 뷰는 갱신되어야 하고, db는 이를 자동으로 수행할 수 있다
  - 다만 이런 갱신은 비싸기 때문에 OLTP에서는 구체화 뷰를 자주 사용하지 않는다
- **데이터 큐브(OLAP 큐브)**는 일반화된 구체화 뷰의 특별 사례다 (그림 3-12 참조)
  - n차원 pivot table 만든 느낌?
  - 어떤 질의에 대해 빠르게 선행 연산된 결과를 돌려줄 수 있지만, 원시 데이터만큼 유연하지 않다 


